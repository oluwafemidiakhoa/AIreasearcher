{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkP58WOJjbic5RYIWWBuYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oluwafemidiakhoa/AIreasearcher/blob/main/Climatesheat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch openai\n",
        "!pip install  kaggle\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwRQN_UZwCqT",
        "outputId": "227bfcca-5366-44ed-e0d5-96fa4a3348c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vX3nWL66wAfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "##from transformers import VisionTransformerForImageClassification, ViTFeatureExtractor\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "\n",
        "import openai\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import os\n",
        "import openai  # OpenAI's Python library\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "from google.colab import userdata\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irDfeLfUETVD",
        "outputId": "ecc1a2b6-7af3-411f-d86f-4dda6acd9c0d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API clients initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Importing necessary libraries\n",
        "import os\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "import openai\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import folium\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Set environment variables for OpenAI and Kaggle credentials\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")\n",
        "os.environ[\"HF_TOKEN\"]= userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = openai.Client(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Initialize Kaggle API client\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "print(\"API clients initialized successfully.\")\n",
        "\n",
        "# Step 1: Download and Load Climate-Related Datasets from Kaggle\n",
        "def download_kaggle_dataset(dataset_slug, dataset_path):\n",
        "    \"\"\"Download a dataset from Kaggle.\"\"\"\n",
        "    api.dataset_download_files(dataset_slug, path=dataset_path, unzip=True)\n",
        "    print(f\"Dataset downloaded to {dataset_path}.\")\n",
        "\n",
        "# Example Kaggle dataset: Climate Change Earth Surface Temperature Data\n",
        "download_kaggle_dataset(\"berkeleyearth/climate-change-earth-surface-temperature-data\", \"./data\")\n",
        "climate_data = pd.read_csv(\"./data/GlobalTemperatures.csv\")\n",
        "\n",
        "# Step 2: Preprocess the Dataset\n",
        "def preprocess_climate_data(df):\n",
        "    \"\"\"Preprocess climate data for analysis.\"\"\"\n",
        "    df[\"dt\"] = pd.to_datetime(df[\"dt\"])\n",
        "    df[\"Year\"] = df[\"dt\"].dt.year\n",
        "    df = df.groupby(\"Year\").mean().reset_index()\n",
        "    return df\n",
        "\n",
        "climate_data = preprocess_climate_data(climate_data)\n",
        "\n",
        "# Step 3: Train a Climate Insight Model using Hugging Face\n",
        "def train_nlp_model():\n",
        "    \"\"\"Train or fine-tune an NLP model for climate text analysis.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "    climate_texts = [\"Global warming is causing ice caps to melt.\", \"The carbon emissions are reducing due to policy changes.\"]\n",
        "    labels = [1, 0]  # 1: Problematic, 0: Positive\n",
        "\n",
        "    inputs = tokenizer(climate_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    labels = torch.tensor(labels).unsqueeze(0)\n",
        "\n",
        "    outputs = model(**inputs, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "    print(f\"Training loss: {loss.item()}\")\n",
        "\n",
        "train_nlp_model()\n",
        "\n",
        "# Step 4: Generate Policy Insights using OpenAI GPT\n",
        "def generate_policy_recommendations(prompt):\n",
        "    \"\"\"Generate policy recommendations using OpenAI GPT.\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=500,\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "policy_prompt = \"Propose climate change mitigation policies based on rising global temperatures and CO2 levels.\"\n",
        "policy_recommendations = generate_policy_recommendations(policy_prompt)\n",
        "print(\"Policy Recommendations:\")\n",
        "print(policy_recommendations)\n",
        "\n",
        "# Step 5: Combine with Geospatial Data Visualization\n",
        "def visualize_geospatial_data(df):\n",
        "    \"\"\"Visualize climate data on a world map using Folium.\"\"\"\n",
        "    map_center = [20, 0]  # Approximate center of the world map\n",
        "    world_map = folium.Map(location=map_center, zoom_start=2)\n",
        "\n",
        "    # Example: Highlight countries based on temperature anomalies\n",
        "    for _, row in df.iterrows():\n",
        "        folium.CircleMarker(\n",
        "            location=[row[\"latitude\"], row[\"longitude\"]],\n",
        "            radius=5,\n",
        "            color=\"red\",\n",
        "            fill=True,\n",
        "            fill_color=\"red\",\n",
        "            tooltip=f\"Temp: {row['temperature']:.2f}°C\"\n",
        "        ).add_to(world_map)\n",
        "\n",
        "    # Save and display the map\n",
        "    world_map.save(\"climate_map.html\")\n",
        "    print(\"Geospatial visualization saved as climate_map.html.\")\n",
        "\n",
        "# Example geospatial data\n",
        "geospatial_data = pd.DataFrame({\n",
        "    \"latitude\": [51.5, -33.9, 35.6],\n",
        "    \"longitude\": [-0.1, 151.2, 139.7],\n",
        "    \"temperature\": [15.5, 18.7, 20.3]\n",
        "})\n",
        "\n",
        "visualize_geospatial_data(geospatial_data)\n",
        "\n",
        "# Step 6: Combine Multimodal Insights\n",
        "def generate_multimodal_climate_report(climate_df, policy_text, map_file):\n",
        "    \"\"\"Generate a multimodal climate report.\"\"\"\n",
        "    report = f\"\"\"\n",
        "    ## Climate Report\n",
        "\n",
        "    ### Global Temperature Trends\n",
        "    {climate_df.to_markdown()}\n",
        "\n",
        "    ### Policy Recommendations\n",
        "    {policy_text}\n",
        "\n",
        "    ### Visualization\n",
        "    See the attached geospatial map: {map_file}.\n",
        "    \"\"\"\n",
        "    with open(\"climate_report.md\", \"w\") as f:\n",
        "        f.write(report)\n",
        "    print(\"Multimodal climate report generated: climate_report.md\")\n",
        "\n",
        "generate_multimodal_climate_report(climate_data, policy_recommendations, \"climate_map.html\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RnGCSFsmURB",
        "outputId": "b113b00d-4046-4b6f-e055-2ea237e9e433"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API clients initialized successfully.\n",
            "Dataset URL: https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data\n",
            "Dataset downloaded to ./data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.7010793089866638\n",
            "Policy Recommendations:\n",
            "1. Energy Efficiency and Conservation: The government should introduce new regulations that compel industries and homes to adopt energy-efficient practices. This includes using energy-saving appliances and the use of green energy technology. \n",
            "\n",
            "2. Carbon Pricing: Policymakers should consider establishing or enhancing programs that put a price on carbon emissions such as carbon taxes or cap-and-trade systems.\n",
            "\n",
            "3. Renewable Energy Transition: Governments must invest in renewable energy technologies like solar, wind, and hydroelectric power to lower reliance on fossil fuels and thus lower CO2 emissions. \n",
            "\n",
            "4. Forestation and Reforestation: Develop forest management policies to increase carbon absorption capacity, incentivize the planting of trees, and make policies against deforestation more stringent.\n",
            "\n",
            "5. Agriculture Management: Reform agricultural practices to enhance soil carbon sequestration, manage livestock GHG emissions, and to reduce the overall carbon footprint of food production.\n",
            "\n",
            "6. Transportation: Promote electric and hybrid vehicles through incentives and improving infrastructure for electric vehicles. Enhance public transportation, encourage carpooling, and consider implementing regional planning that reduces daily commutes.\n",
            "\n",
            "7. Waste Management: Improve waste management practices to cut down on the amount of CO2 released in waste processing.\n",
            "\n",
            "8. Renewable Fuels Technology: Increase funding for research and development of new technologies such as carbon capture and sequestration, climate engineering, and advanced renewable fuels.\n",
            "\n",
            "9. Green Building Practices: Governments should enforce building regulations that require all new structures to adhere to green building practices to ensure they are more energy-efficient.\n",
            "\n",
            "10. Public Awareness and Education: Implement programs to educate the public about climate change implications and what individuals can do to reduce their carbon footprints. This could help spur behavioral changes, creating a shift towards more sustainable living.\n",
            "\n",
            "11. Encourage International Cooperation: Climate change is a global problem and requires all nations to participate in its mitigation. Governments should actively participate in global efforts to reduce CO2 emissions, such as the Paris Agreement.\n",
            "\n",
            "12. Implement Sustainable Development Goals: Adopt and continue to pursue achievable sustainable development goals (SDGs) to reduce the impact of climate change on our planet.\n",
            "Geospatial visualization saved as climate_map.html.\n",
            "Multimodal climate report generated: climate_report.md\n"
          ]
        }
      ]
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "Lg5eIprwzwW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}